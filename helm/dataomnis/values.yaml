# Default values for dataomnis.
# This is a YAML-formatted file.
# Declare variables to be passed into your templates.

# for apiserver and flink web
domain: dataomnis.192.168.27.90.nip.io
port:

# the host info for pod
# qingcloudApiIP: the ip of api.qingcloud.com
dns:
  qingcloudApiIP: 172.31.60.141

image:
  # kubectl -n dataomnis create secret docker-registry docker-registry-secret --docker-server=dockerhub.qingcloud.com --docker-username=push-dataomnis --docker-password=<your-pword>
  # if need, first create docker-registry secret named "docker-registry-secret" by above cmd in namespace dataomnis and set secret to "docker-registry-secret"
  pullSecret:
  pullPolicy: Always  # pullPolicy: IfNotPresent

  registry: dockerhub.dataomnis.io
  tag: dev
  zeppelinTag: 0.9.0

  busybox: busybox:1.28.4
  jaeger: jaegertracing/all-in-one:1.22

# common configuration for all service
common:
  replicas: 1
  strategy: RollingUpdate
  logLevel: 1  # 1=>"debug", 2=>"info", 3=>"warn", 4=>"error", 5=>"fatal"
  logOutput: "file" # "console" or "file"
  grpcLog:
    level: 2  #  1 => info, 2 => waring, 3 => error, 4 => fatal
    verbosity: 99
  metrics:
    enabled: true
    urlPath: "/metrics"
  livenessProbe:
    initialDelaySeconds: 10
    periodSeconds: 15
  readinessProbe:
    periodSeconds: 10
    initialDelaySeconds: 20

persistent:
  hostPath: /data/dataomnis/dataomnis

etcd:
  endpoint: etcd-cluster

# mysql configuration
mysql:
  internal: false  # if use internal mysql in dependencies
  # common mysql configuration for dataomnis services
  externalHost: mysql-cluster-pxc-db-haproxy
  secretName: mysql-cluster-pxc-db
  user: "root"
  database: "dataomnis"
  maxIdleConn: 16
  maxOpenConn: 128
  connMaxLifetime: 10m
  logLevel: 4  # 1 => Silent, 2 => Error, 3 => Warn, 4 => Info
  slowTshreshold: 2s

hdfs:
  configmapName: hdfs-cluster-common-config

# redis-cluster configuration
redis:
  address: rfs-redis-cluster
  database: 0
  masterName: "mymaster"

# apiglobal settings
apiglobal:
  enabled: true
  httpServer:
    read_timeout: 30s
    write_timeout: 30s
    idle_timeout: 30s
    exit_timeout: 5m

  # region settings
  regions:
    testing:
      hosts: "http://api.dataomnis.192.168.27.90.nip.io" # apiserver export service
      names:
        zh_cn: "开发测试区"
        en_us: "testing"
  # authentication
  authentication:
    identity_providers:
      enfi:
        name: enfi
        client_id: "9034819z8a161e5a809c"
        client_secret: "785v4f1551785df46b64baf8ikj931cfc72b087dc"
        token_url: "http://x6ftpx.natappfree.cc/sys/BigDataOauth/accessToken"
        redirect_url: "http://global.dataomnis.192.168.27.90.nip.io/v1/auth/redirect/enfi"
  # http proxy
  http_proxy: "http://172.20.0.6:8888"

  envs: {}

# apiserver configuration
apiserver:
  httpServer:
    read_timeout: 30s
    write_timeout: 30s
    idle_timeout: 30s
    exit_timeout: 5m
  envs:

# account configuration
account:
  source: "qingcloud"
  envs:

# enginemanager configuration
enginemanager:
  kubeConfPath: "/root/.kube/config"
  helm:
    repoConfig: "/root/.config/helm/repositories.yaml"
    repoCachePath: "/root/.cache/helm/repository"
    debug: false

  flink:
    restServicePort: 8081
    restServiceNameFmt: "%s-flink-jobmanager-rest"
    ingressClass: "nginx"
    enableMultus: false

  envs: {}

# resourcemanager configuration
resourcemanager:
  storage:
    background: "hdfs"
    hadoopConfDir: "/etc/hadoop/conf"
    s3:
      endpoint: "s3.gd2.qingstor.com"
      region: "gd2" # us-west-2
      bucket: "demo-yu-gd2-15"

  envs: {}

# scheduler configuration
scheduler:
  etcdDialTimeout: 5s

  streamJobCrontabRetryInterval: 120s
  streamJobCheckInstanceStateInterval: 30s
  syncJobCrontabRetryInterval: 120s
  syncJobCheckInstanceStateInterval: 30s

  envs: {}

# spacemanager configuration
spacemanager:
  envs: {}

developer:
  envs:
    DEVELOPER_SPACE_MANAGER_SERVER_ENABLEKEEPALIVE: true
    DEVELOPER_SPACE_MANAGER_SERVER_KEEPALIVEWITHOUTCALLS: true
    DEVELOPER_SPACE_MANAGER_SERVER_NEGOTIATIONTYPE: plaintext

# jaeger configuration
jaeger:
  envs:
    COLLECTOR_ZIPKIN_HTTP_PORT: 9411

# iaas configuration
iaas:
  zone: "testing"
  protocol: "http"
  host: "api.testing.com"
  port: "7777"
  uri: "/iaas/"
  timeout: 600
  access_key_id: "LTMJGBXPHSEZRNVKKPHU"
  secret_access_key: "7GvVuGAx2iB8NA9n8NtczH8BJnTkDGwGm9N6DYBo"

# serviceName: port
ports:
  jaeger: 6831
  jaegerweb: 16686
  mysql: 3306
  etcd: 2379
  zeppelin: 8080
  hdfs: 8020
  redis: 26379  # keep same as the port of redis cluster (Sentinel-Mode)

  apiglobal: 8001
  apiserver: 9001
  spacemanager: 9101
  scheduler: 9103
  jobmanager: 9105
  account: 9110
  resourcemanager: 9111
  notifier: 9113
  enginemanager: 9114
  developer: 9119

metricsPorts: # key must be same as component in deployment
  spacemanager: 9201
  scheduler: 9203
  jobmanager: 9205
  account: 9210
  resourcemanager: 9211
  notifier: 9213
  enginemanager: 9214
  developer: 9219

serviceMonitor:
  enabled: true
  defaults:
    labels:
      project: dataomnis
  namespace: kubesphere-monitoring-system
  port: metrics
  interval: 30s

web:
  enabled: false
