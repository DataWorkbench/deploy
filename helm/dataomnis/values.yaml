# Default values for dataomnis.
# This is a YAML-formatted file.
# Declare variables to be passed into your templates.

# for api and flink web
domain: dataomnis.192.168.27.90.nip.io
port:

image:
  # kubectl -n dataomnis create secret docker-registry docker-registry-secret --docker-server=dockerhub.qingcloud.com --docker-username=push-dataomnis --docker-password=<your-pword>
  # if need, first create docker-registry secret named "docker-registry-secret" by above cmd in namespace dataomnis and set secret to "docker-registry-secret"
  pullSecrets: []
  pullPolicy: Always  # pullPolicy: IfNotPresent

  registry: dockerhub.dataomnis.io
  tag: dev
  zeppelinTag: 0.9.0

  busybox: busybox:1.28.4
  jaeger: jaegertracing/all-in-one:1.22

# common configuration for all service
common:
  replicas: 1
  strategy: RollingUpdate

  logLevel: 1  # 1=>"debug", 2=>"info", 3=>"warn", 4=>"error", 5=>"fatal"
  logOutput: "file" # "console" or "file"
  grpcLog:
    level: 2  #  1 => info, 2 => waring, 3 => error, 4 => fatal
    verbosity: 99
  metrics:
    enabled: true
    urlPath: "/metrics"

  livenessProbe:
    initialDelaySeconds: 20
    periodSeconds: 30
  readinessProbe:
    initialDelaySeconds: 20
    periodSeconds: 10

persistent:
  hostPath: /data/dataomnis/dataomnis

etcd:
  endpoint: etcd-cluster

# mysql configuration
mysql:
  internal: false  # if use internal mysql in dependencies
  # common mysql configuration for dataomnis services
  externalHost: mysql-cluster-pxc-db-haproxy
  secretName: mysql-cluster-pxc-db
  user: "root"
  database: "dataomnis"
  maxIdleConn: 16
  maxOpenConn: 128
  connMaxLifetime: 10m
  logLevel: 4  # 1 => Silent, 2 => Error, 3 => Warn, 4 => Info
  slowThreshold: 2s

hdfs:
  configmapName: hdfs-cluster-common-config

# redis-cluster configuration
redis:
  mode: "cluster"
  sentinelAddr: ""
  clusterAddr: "redis-cluster-0:6379,redis-cluster-1:6379,redis-cluster-2:6379"
  masterName: "mymaster"
  database: 0
  username: ""
  password: ""

# apiglobal settings
apiglobal:
  enabled: true
  resources:
    limits:
      cpu: 2000m
      memory: 4096Mi
    requests:
      cpu: 100m
      memory: 100Mi
  httpServer:
    readTimeout: 30s
    writeTimeout: 30s
    idleTimeout: 30s
    exitTimeout: 5m

  # region settings
  regions:
    testing:
      hosts: "http://api.dataomnis.192.168.27.90.nip.io" # apiserver export service
      names:
        zh_cn: "开发测试区"
        en_us: "testing"
  # authentication
  authentication:
    identityProviders:
      enfi:
        name: enfi
        clientId: "9034819z8a161e5a809c"
        clientSecret: "785v4f1551785df46b64baf8ikj931cfc72b087dc"
        tokenUrl: "http://x6ftpx.natappfree.cc/sys/BigDataOauth/accessToken"
        redirectUrl: "http://global.dataomnis.192.168.27.90.nip.io/v1/auth/redirect/enfi"
  # http proxy
  httpProxy: "http://172.20.0.6:8888"

  envs: {}


# apiserver configuration
apiserver:
  resources:
    limits:
      cpu: 2048m
      memory: 4096Mi
    requests:
      cpu: 100m
      memory: 100Mi
  httpServer:
    readTimeout: 30s
    writeTimeout: 30s
    idleTimeout: 30s
    exitTimeout: 5m
  envs: {}


# account configuration
account:
  resources:
    limits:
      cpu: 2048m
      memory: 4096Mi
    requests:
      cpu: 100m
      memory: 100Mi
  source: "qingcloud"
  envs: {}


# enginemanager configuration
enginemanager:
  resources:
    limits:
      cpu: 1024m
      memory: 2048Mi
    requests:
      cpu: 100m
      memory: 100Mi

  helm:
    repoConfig: "/root/.config/helm/repositories.yaml"
    repoCachePath: "/root/.cache/helm/repository"
    debug: false

  flink:
    restServicePort: 8081
    restServiceNameFmt: "%s-flink-jobmanager-rest"
    ingressClass: "nginx"
    enableMultus: false

  envs: {}

# resourcemanager configuration
resourcemanager:
  resources:
    limits:
      cpu: 1024m
      memory: 2048Mi
    requests:
      cpu: 100m
      memory: 100Mi
  storage:
    background: "hdfs"
    hadoopConfDir: "/etc/hadoop/conf"
    s3:
      endpoint: "s3.gd2.qingstor.com"
      region: "gd2" # us-west-2
      bucket: "demo-yu-gd2-15"
      accessKeyId: ""
      secretAccessKey: ""

  envs: {}

# scheduler configuration
scheduler:
  resources:
    limits:
      cpu: 1024m
      memory: 2048Mi
    requests:
      cpu: 100m
      memory: 100Mi

  etcdDialTimeout: 5s
  envs: {}

# spacemanager configuration
spacemanager:
  resources:
    limits:
      cpu: 1024m
      memory: 2048Mi
    requests:
      cpu: 100m
      memory: 100Mi
  envs: {}

developer:
  resources:
    limits:
      cpu: 1024m
      memory: 2048Mi
    requests:
      cpu: 100m
      memory: 100Mi
  envs:
    DEVELOPER_SPACE_MANAGER_SERVER_ENABLEKEEPALIVE: true
    DEVELOPER_SPACE_MANAGER_SERVER_KEEPALIVEWITHOUTCALLS: true
    DEVELOPER_SPACE_MANAGER_SERVER_NEGOTIATIONTYPE: plaintext

# jaeger configuration
jaeger:
  envs:
    COLLECTOR_ZIPKIN_HTTP_PORT: 9411

# iaas configuration
iaas: {}
#  zone: "testing"
#  protocol: "http"
#  host: "172.31.60.141"
#  port: "7777"
#  uri: "/iaas/"
#  timeout: 600
#  accessKeyId: "LTMJGBXPHSXXXXXXXXXX"
#  secretAccessKey: "7GvVuGAx2iB8NA9n8NtczH8BJnTkDGwGm9N6DYBo"

# serviceName: port
ports:
  jaeger: 6831
  jaegerweb: 16686
  mysql: 3306
  etcd: 2379
  zeppelin: 8080
  hdfs: 8020

  apiglobal: 8001
  apiserver: 9001
  spacemanager: 9101
  scheduler: 9103
  account: 9110
  resourcemanager: 9111
  enginemanager: 9114
  developer: 9119
  developerHttp: 9219

# add serviceMonitor for service(key must be same as component in deployment);
# the serviceMonitor would be auto created if add the metricsPorts of service below.
metricsPorts:
  spacemanager: 9201
  scheduler: 9203
  jobmanager: 9205
  account: 9210
  resourcemanager: 9211
  enginemanager: 9214

serviceMonitor:
  enabled: false
  defaults:
    labels:
      project: dataomnis
  namespace: kubesphere-monitoring-system
  port: metrics
  interval: 30s

webservice:
  enabled: false
  resources:
    limits:
      cpu: 2048m
      memory: 4096Mi
    requests:
      cpu: 100m
      memory: 100Mi

filebeat:
  enabled: true
