# Default values for databench.
# This is a YAML-formatted file.
# Declare variables to be passed into your templates.

# for apiserver and flink web
domain: databench.192.168.27.90.nip.io
#
dns:
  ksLBIP: 172.20.0.2
  qingcloudApiIP: 172.31.60.141

image:
#  pullPolicy: IfNotPresent
  pullPolicy: Always

  databench: dockerhub.databench.io/databench/databench:dev
  flyway: dockerhub.databench.io/databench/flyway:dev
  zeppelin: dockerhub.databench.io/databench/zeppelin:0.9.0
  zeppelinInterpreter: dockerhub.databench.io/databench/zeppelin:0.9.0
  web: dockerhub.qingcloud.com/databench/web:0.1.0

  jaeger: jaegertracing/all-in-one:1.22

# common configuration for all service
common:
  replicas: 1
  strategy: RollingUpdate
  logLevel: 1  # 1=>"debug", 2=>"info", 3=>"warn", 4=>"error", 5=>"fatal"
  grpcLog:
    level: 2  #  1 => info, 2 => waring, 3 => error, 4 => fatal
    verbosity: 99
  metrics:
    enabled: true
    urlPath: "/metrics"
  livenessProbe:
    initialDelaySeconds: 10
    periodSeconds: 15
  readinessProbe:
    periodSeconds: 10
    initialDelaySeconds: 20

etcd:
  endpoint: etcd-cluster-client

# mysql configuration
mysql:
  internal: false  # if use internal mysql in dependencies
  # common mysql configuration for databench services
  externalHost: mysql-cluster-pxc-db-haproxy
  secretName: mysql-cluster-pxc-db
  user: "root"
  database: "data_workbench"
  maxIdleConn: 16
  maxOpenConn: 128
  connMaxLifetime: 10m
  logLevel: 4  # 1 => Silent, 2 => Error, 3 => Warn, 4 => Info
  slowTshreshold: 2s

hdfs:
  configmapName: hdfs-common-config

# redis-cluster configuration
redis:
  address: rfs-redis-cluster
  database: 0
  masterName: "mymaster"

# apiglobal settings
apiglobal:
  # region settings
  regions:
    testing:
      hosts: "http://api.databench.192.168.27.90.nip.io" # apiserver export service
      names:
        zh_cn: "开发测试区"
        en_us: "testing"
  envs:
    API_GLOBAL_HTTP_SERVER_READ_TIMEOUT: 30s
    API_GLOBAL_HTTP_SERVER_WRITE_TIMEOUT: 30s
    API_GLOBAL_HTTP_SERVER_DLE_TIMEOUT: 30s
    API_GLOBAL_HTTP_SERVER_EXIT_TIMEOUT: 5m
    API_GLOBAL_TRACER_SERVICE_NAME: apiglobal

# apiserver configuration
apiserver:
  envs:
    API_SERVER_READ_TIMEOUT: 30s
    API_SERVER_WRITE_TIMEOUT: 30s
    API_SERVER_DLE_TIMEOUT: 30s
    API_SERVER_EXIT_TIMEOUT: 5m
    API_SERVER_TRACER_SERVICE_NAME: "apiserver"
    API_SERVER_REGION_ID: "testing"

# account configuration
account:
  envs:
    ACCOUNT_TRACER_SERVICE_NAME: "account"
    ACCOUNT_SOURCE: "qingcloud"

# enginemanager configuration
enginemanager:
  replicas: 1
  helmRepoPath: "/root/.cache/helm/repository"
  kubeConfigPath: "/root/.kube/config"
  envs:
    ENGINE_MANAGER_LOG_LEVEL: 1
    ENGINE_MANAGER_GRPC_LOG_LEVEL: 1
    ENGINE_MANAGER_TRACER_SERVICE_NAME: "enginemanager"
    ENGINE_MANAGER_KUBE_CONF_PATH: "/root/.kube/config"
    ENGINE_MANAGER_HELM_REPOSITORY_CONFIG: "/root/.config/helm/repositories.yaml"
    ENGINE_MANAGER_HELM_REPOSITORY_CACHE: "/root/.cache/helm/repository"
    ENGINE_MANAGER_HELM_DRIVER: ""
    ENGINE_MANAGER_HELM_DEBUG: false
    ENGINE_MANAGER_HELM_QUERY_STATUS_DURATION: 10

    ENGINE_MANAGER_FLINK_IMAGE_REPO: "dockerhub.databench.io/databench/flink"
    ENGINE_MANAGER_FLINK_REST_SERVICE_PORT: "8081"
    ENGINE_MANAGER_FLINK_REST_SERVICE_NAME_FMT: "%s-flink-jobmanager-rest"
    ENGINE_MANAGER_FLINK_INGRESS_CLASS: "nginx"

# flowmanager configuration
flowmanager:
  envs:
    FLOW_MANAGER_TRACER_SERVICE_NAME: flowmanager

# jobdeveloper configuration
jobdeveloper:
  envs:
    JOB_DEVELOPER_TRACER_SERVICE_NAME: "jobdeveloper"
    JOB_DEVELOPER_ZEPPELIN_FLINK_HOME: "/zeppelin/flink/flink-1.12.3"
    JOB_DEVELOPER_ZEPPELIN_FLINK_EXECUTE_JARS: "MySQL:/zeppelin/flink/1.12_lib/flink-connector-jdbc_2.11-1.12.3.jar,/zeppelin/flink/1.12_lib/mysql-connector-java-8.0.21.jar;PostgreSQL:/zeppelin/flink/1.12_lib/flink-connector-jdbc_2.11-1.12.3.jar,/zeppelin/flink/1.12_lib/postgresql-42.2.18.jar;Kafka:/zeppelin/flink/1.12_lib/flink-sql-connector-kafka_2.11-1.12.3.jar;ClickHouse:/zeppelin/flink/1.12_lib/flink-connector-jdbc_2.11-1.12.3.jar,/zeppelin/flink/1.12_lib/flink-connector-clickhouse-1.0.0.jar;HBase:/zeppelin/flink/1.12_lib/flink-shaded-hadoop-2-uber-2.8.3-10.0.jar,/zeppelin/flink/1.12_lib/flink-sql-connector-hbase-2.2_2.11-1.12.3.jar;Ftp:/zeppelin/flink/1.12_lib/flink-connector-ftp_2.11_1.12.0.jar,/zeppelin/flink/1.12_lib/flink-csv-1.12.2.jar,/zeppelin/flink/1.12_lib/flink-json-1.12.2.jar,/zeppelin/flink/1.12_lib/flink-sql-connector-elasticsearch7_2.11-1.12.3.jar,/zeppelin/flink/1.12_lib/flink-connector-mysql-cdc-1.3.0.jar"
    JOB_DEVELOPER_ZEPPELIN_HADOOP_CONF: "/zeppelin/hadoop/hadoop-2.7.5/etc/hadoop"

# jobmanager configuration
jobmanager:
  envs:
    JOB_MANAGER_TRACER_SERVICE_NAME: "jobmanager"

# jobwatcher configuration
jobwatcher:
  envs:
    JOB_WATCHER_JOB_WORKS: 16
    JOB_WATCHER_PICKUP_ALONE_JOBS: 1
    JOB_WATCHER_TRACER_SERVICE_NAME: "jobwatcher"

# logmanager configuration
logmanager:
  envs:
    LOG_MANAGER_TRACER_SERVICE_NAME: "logmanager"
    LOG_MANAGER_HDFS_SERVER_USER_NAME: "root"
    LOG_MANAGER_HDFS_SERVER_BUFFER_SIZE: 1024

# notifier configuration
notifier:
  envs:
    NOTIFIER_NF_CONFIG_CHANNEL: "SMTPChannel"
    NOTIFIER_NF_CONFIG_SDK_CONFIG_ACCESS_KEY_ID: "IKSMDBWVIECPIVNDYZAB"
    NOTIFIER_NF_CONFIG_SDK_CONFIG_SECRET_ACCESS_KEY: "JnEco2qZ6EvXt89mJpCVdkBoc5AwPA0unrkFkOxq"
    NOTIFIER_NF_CONFIG_SDK_CONFIG_HOST: "api.alphacloud.com"
    NOTIFIER_NF_CONFIG_SDK_CONFIG_PORT: 7777
    NOTIFIER_NF_CONFIG_SDK_CONFIG_PROTOCOL: "http"
    NOTIFIER_NF_CONFIG_SDK_CONFIG_URI: "/iaas"
    NOTIFIER_NF_CONFIG_SMTP_CONFIG_HOST: "smtp.163.com"
    NOTIFIER_NF_CONFIG_SMTP_CONFIG_PORT: 25
    NOTIFIER_NF_CONFIG_SMTP_CONFIG_USER_NAME: "xiaobai417sos@163.com"
    NOTIFIER_NF_CONFIG_SMTP_CONFIG_PASSWORD: "82717785"

# observer configuration
observer:
  envs: {}

# resourcemanager configuration
resourcemanager:
  envs:
    RESOURCE_MANAGER_HADOOP_CONF_DIR: /etc/hadoop

# scheduler configuration
scheduler:
  envs:
    SCHEDULER_TRACER_SERVICE_NAME: "scheduler"
    SCHEDULER_ETCD_DIAL_TIMEOUT: 5s

# sourcemanager configuration
sourcemanager:
  envs:
    SOURCE_MANAGER_TRACER_SERVICE_NAME: "sourcemanager"

# spacemanager configuration
spacemanager:
  envs:
    SPACE_MANAGER_TRACER_SERVICE_NAME: "spacemanager"
    SPACE_MANAGER_ETCD_DIAL_TIMEOUT: 5s

# udfmanager configuration
udfmanager:
  envs:
    UDF_MANAGER_TRACER_SERVICE_NAME: "udfmanager"

# zeppelin configuration
zeppelin:
  hdfsConfigDir: /zeppelin/hadoop/hadoop-2.7.5/etc/hadoop
  envs:
    ZEPPELIN_HOME: /opt/zeppelin
    ZEPPELIN_SERVER_RPC_PORTRANGE: 12320:12320
    ZEPPELIN_K8S_SPARK_CONTAINER_IMAGE: spark:2.4.5
    SPARK_MASTER: k8s://https://kubernetes.default.svc
    SPARK_HOME: /spark

# jaeger configuration
jaeger:
  envs:
    COLLECTOR_ZIPKIN_HTTP_PORT: 9411

# iaas configuration
iaas:
  zone: "testing"
  protocol: "http"
  host: "api.testing.com"
  port: "7777"
  uri: "/iaas/"
  timeout: 600
  access_key_id: "LTMJGBXPHSEZRNVKKPHU"
  secret_access_key: "7GvVuGAx2iB8NA9n8NtczH8BJnTkDGwGm9N6DYBo"

# serviceName: port
ports:
  jaeger: 6831
  jaegerweb: 16686
  mysql: 3306
  etcd: 2379
  zeppelin: 8080
  hdfs: 8020
  redis: 26379  # keep same as the port of redis cluster (Sentinel-Mode)

  apiglobal: 8001
  apiserver: 9001
  spacemanager: 9101
  flowmanager: 9102
  scheduler: 9103
  sourcemanager: 9104
  jobmanager: 9105
  udfmanager: 9106
  jobwatcher: 9108
  jobdeveloper: 9109
  account: 9110
  resourcemanager: 9111
  observer: 9112
  notifier: 9113
  enginemanager: 9114
  logmanager: 9115

metricsPorts: # key must be same as component in deployment
  spacemanager: 9201
  flowmanager: 9202
  scheduler: 9203
  sourcemanager: 9204
  jobmanager: 9205
  udfmanager: 9206
  jobwatcher: 9208
  jobdeveloper: 9209
  account: 9210
  resourcemanager: 9211
#  observer: 9212
  notifier: 9213
  enginemanager: 9214
#  logmanager: 9215

serviceMonitor:
  enabled: true
  defaults:
    labels:
      project: databench
  namespace: kubesphere-monitoring-system
  port: metrics
  interval: 30s

web:
  enabled: false
